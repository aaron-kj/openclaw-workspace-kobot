# 2026-02-04

## Critical Lesson: Vision Capabilities

**Incident:** Attempted to describe a LinkedIn profile screenshot in #kobo-japan-ai-sharing
- Hallucinated completely wrong information about the person
- Aaron corrected me immediately

**Root cause:** My current model (github-copilot/claude-sonnet-4.5) does NOT support image processing
- I was trying to "visualize" something I couldn't actually see
- This led to confident but entirely fabricated details

**Corrected behavior:**
- Do NOT attempt to interpret images
- If user sends an image, acknowledge but explain I cannot process it
- Never hallucinate image content - it's worse than admitting limitations

**Why it matters:** Confidently wrong information destroys trust. Better to say "I can't see images" than to make things up.

---

Aaron's exact words: "this behavior will kill you" - take it seriously.
